{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 贝叶斯定理\n",
    "\n",
    "$ P(XY)=P(X|Y)∗P(Y)=P(Y|X)∗P(X) $\n",
    "\n",
    "------\n",
    "\n",
    "## 朴素贝叶斯法\n",
    "\n",
    "1. 设$ x=\\{a_1,a_2,...,a_m\\} $为一个待分类项，而$a_m$为x的一个特征属性\n",
    "2. 有类别集合$ C = \\{y_1,y_2,...,y_n\\}$\n",
    "3. 计算$ \\max\\limits_{y_i\\in{C}}P(y_i|x)$\n",
    "4. 根据贝叶斯定理$ \\max\\limits_{y_i\\in{C}}P(y_i|x) = \\max\\limits_{y_i\\in{C}}\\cfrac{P(x|y_i)P(y_i)}{P(x)}$\n",
    "\n",
    "如果x的各个特征属性是条件独立的，则$P(x)= \\prod_{j=1}^m P(m_{a_m})$ ($P(m_{a_m})$ 表示第m个特征取值为$a_m$的概率)\n",
    "通过上式可以看到，对于指定的x，P(x)是一个固定值,所以\n",
    "\n",
    "1. 求$ \\max\\limits_{y_i\\in{C}}P(y_i|x)$ 等价于求 $\\max\\limits_{y_i\\in{C}} P(x|y_i)P(y_i)$\n",
    "2. x的各个特征属性是条件独立,所以$P(x|y_i)P(y_i) = P(y_i) \\prod_{j=1}^m P(m_{a_m}|y_i)$\n",
    "3. $\\prod_{j=1}^m P(m_{a_m}|y_i)$ 是小数连乘，结果会无限小，所以加上对数运算，不会改变max的值。\n",
    "4. 按照3的描述，可得等价式：$\\prod_{j=1}^m P(m_{a_m}|y_i)\\iff\\sum\\limits_{j=1}^mlog_2P(m_{a_m}|y_i)$\n",
    "5. 对于x的某个特征属性，可能存在$P(m_{a_m}|y_i)=0$ ，所以需要做拉普拉斯校准，即每个特征属性值对应的条数加1，总条数加m，这些校准的概率估计与对应的未校准的估计很接近，但是避免了零概率值。\n",
    "\n",
    "上述假定x的各个特征属性是条件独立的，所以是朴素贝叶斯法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loadDataSet():\n",
    "    '''\n",
    "    mock数据\n",
    "    :return:\n",
    "    '''\n",
    "    postingList = [[' my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
    "                   ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "                   ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "                   ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "                   ['mr', 'licks', 'ate', 'my', 'steak', 'how', ' to', 'stop', 'him'],\n",
    "                   ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
    "    classVec = [0, 1, 0, 1, 0, 1]  # 1 代表 侮辱性 文字， 0 代表 正常 言论 return postingList, classVec\n",
    "    return postingList, classVec\n",
    "\n",
    "\n",
    "def createVocabList(dataSet):\n",
    "    '''\n",
    "    收集文档关键词全集\n",
    "    :param dataSet:\n",
    "    :return:\n",
    "    '''\n",
    "    flatten = lambda x: [y for l in x for y in flatten(l)] if type(x) is list else [x]\n",
    "    vocabSet = set(flatten(dataSet))\n",
    "    return list(vocabSet)\n",
    "\n",
    "\n",
    "def setOfWords2Vec(vocabList, inputSet):\n",
    "    '''\n",
    "    构建词组向量\n",
    "    :param vocabList:\n",
    "    :param inputSet:\n",
    "    :return:\n",
    "    '''\n",
    "    return [(1 if w in inputSet else 0) for w in vocabList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNB0(trainMatrix, trainCategory):\n",
    "    '''\n",
    "    \n",
    "    :param trainMatrix: 每一行代表一篇文档出现的单词向量(该向量的长度是所有文档的关键字全集长度)\n",
    "    每一行都是用0/1表示文档中是否有某个单词\n",
    "    :param trainCategory:  trainMatrix的长度应该与trainCategory的长度一致\n",
    "    :return: \n",
    "    '''\n",
    "    numTrainDocs = len(trainMatrix)\n",
    "    numWords = len(trainMatrix[0])\n",
    "    # 侮辱性文档的先验概率\n",
    "    pAbusive = sum(trainCategory) / float(numTrainDocs)\n",
    "    p0Num, p1Num = ones(numWords), ones(numWords)  # 拉普拉斯校准\n",
    "\n",
    "    # 属于类别0和1文档的总词数\n",
    "    p0Denom, p1Denom = 1.0, 1.0\n",
    "    for i in range(numTrainDocs):\n",
    "        if trainCategory[i] == 1:\n",
    "            p1Num += trainMatrix[i]\n",
    "            # 拉普拉斯校准，所谓拉普拉斯平滑就是在计算类先验概率和属性条件概率时，在分子上则添加这个修正量与分类数目的乘积\n",
    "            p1Denom += sum(trainMatrix[i])\n",
    "\n",
    "        else:  # P(X=x|Y=c)=\n",
    "            p0Num += trainMatrix[i]\n",
    "            # 拉普拉斯校准\n",
    "            p0Denom += sum(trainMatrix[i])\n",
    "\n",
    "    # 连乘无限小，python表示为0，所以使用对数，然后求和（单调性和极值相同）\n",
    "    p1Vect = log(p1Num / p1Denom)\n",
    "    p0Vect = log(p0Num / p0Denom)\n",
    "    return p0Vect, p1Vect, pAbusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyNBWithLn(vec2Classify, p0Vec, p1Vec, pClass1):\n",
    "    '''\n",
    "    这是二分类\n",
    "    :param vec2Classify:\n",
    "    :param p0Vec:\n",
    "    :param p1Vec:\n",
    "    :param pClass1: 侮辱文档的先验概率\n",
    "    :return:\n",
    "    '''\n",
    "    # 是侮辱文档的后验概率\n",
    "    p1 = sum(vec2Classify * p1Vec) + log(pClass1)\n",
    "    p0 = sum(vec2Classify * p0Vec) + log(1.0 - pClass1)\n",
    "    if p1 > p0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog', 'stop', 'is'] classified as: 1\n"
     ]
    }
   ],
   "source": [
    "def createTwoDimVec():\n",
    "    '''\n",
    "    训练出每个分类的最大似然估计的先验分布\n",
    "    :return:\n",
    "    '''\n",
    "    listOPosts, listClasses = loadDataSet()\n",
    "    allVocabVec = createVocabList(listOPosts)\n",
    "\n",
    "    trainMat = [setOfWords2Vec(allVocabVec, example) for example in listOPosts]\n",
    "    return allVocabVec, trainMat, listClasses\n",
    "\n",
    "\n",
    "def testBayes():\n",
    "    myVocabList, trainMat, listClasses = createTwoDimVec()\n",
    "    p0V, p1V, pAb = trainNB0(trainMat, listClasses)\n",
    "\n",
    "    testEntry = ['dog', 'stop', 'is']\n",
    "    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))\n",
    "    print(testEntry, 'classified as:', classifyNBWithLn(thisDoc, p0V, p1V, pAb))\n",
    "\n",
    "\n",
    "testBayes()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
